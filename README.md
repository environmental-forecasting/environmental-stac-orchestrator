# IceNet Dashboard deployment repo

This meta-repository coordinates a modular, containerised icenet dashboard application composed of:

- **[icenet-dashboard-preprocessor](https://github.com/icenet-ai/icenet-dashboard-preprocessor)** – An installable Python package that converts netCDF files to Cloud-Optimised GeoTIFFs (COGs) for use by the tiler.
- **[icenet-tiler-api](https://github.com/icenet-ai/icenet-tiler-api)** – A TiTiler + FastAPI-based backend that serves map tiles and static data.
- **[icenet-dashboard](https://github.com/icenet-ai/icenet-dashboard)** – A Plotly Dash web app for visualising IceNet forecasts.

---

## Repo Structure

```bash
meta-repo/
├── icenet-dashboard/ # Plotly Dash web-app served with Gunicorn
├── icenet-tiler-api/ # Tile and data server using FastAPI + Uvicorn
├── icenet-dashboard-preprocessor/ # Data transformer: NetCDF → COGs
├── data/ # Output COGs and STAC catalog generated by running `icenet-dashboard-preprocessor` on IceNet prediction netCDF files
├── compose.yaml # Orchestrates all containers
└── Makefile # Top-level automation commands
```

---

## Getting Started

### 1. Install Docker

Ensure [Docker](https://docs.docker.com/get-docker/) is installed on your system.

---

### 2. Install and Run IceNet netCDF -> CoG Preprocessor

```bash
pip install -e icenet-dashboard-preprocessor/

icenet_dashboard_preprocess <path_to_icenet_netcdf_predictions>
```

#### Example usage:

To point to a directory with netCDF files:

`icenet_dashboard_preprocess -i results/predict/`

Using wildcards:

`icenet_dashboard_preprocess -i raw_data/*.nc`

This will create a `data/` directory with the JSON catalog and CoG outputs.

```bash
data/
├──  cogs/
│   ├──  north/
│   └──  south/
└──  stac/
    ├──  north/
    ├──  south/
    └──  catalog.json
```

### 3. Build & Launch the Full Stack

```bash
make up
```

This will:

* Build all service images (icenet-dashboard, icenet-tiler-api)
* Launch the dashboard and tile server stack via docker-compose

### 4. Access the UI Interfaces and Docs

* Dashboard UI: http://localhost:8001
* Tiler API: http://localhost:8000
* Data Server: http://localhost:8002

## Environment Configuration (Extreme WIP!)

Each service can be configured via environment variables.

The following environmental variables are set in compose.yaml for consistency across environments.

```bash
TITILER_URL=http://172.17.0.1:8000
DATA_URL=http://172.17.0.1:8002
CATALOG_PATH=http://172.17.0.1:8002/data/stac/catalog.json
```

Note to self: `172.17.0.1` is the default Docker internal network.

There are quite a few duplications (e.g. hostname, ports) to be taken care of since originally each
component of the stack was run independently.

